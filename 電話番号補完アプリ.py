# app.py (ãƒ•ã‚¡ã‚¤ãƒ«å: é›»è©±ç•ªå·è£œå®Œã‚¢ãƒ—ãƒª_v23_modified.py)
import streamlit as st
import pandas as pd
import time
import random
import re
import io
import zipfile
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from urllib.parse import urljoin, quote_plus
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, WebDriverException, NoSuchElementException, InvalidSessionIdException
import sys

# --- â–¼â–¼â–¼ åŸºæœ¬è¨­å®š â–¼â–¼â–¼ ---
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'
]
DECOY_URLS = ['https://www.yahoo.co.jp/', 'https://www.wikipedia.org/', 'https://www.nikkei.com/']

COMPANY_LINK_XPATH = " | ".join([
    "//a[contains(., 'ä¼šç¤¾æ¦‚è¦')]",
    "//a[contains(., 'ä¼æ¥­æƒ…å ±')]",
    "//a[contains(., 'ä¼šç¤¾æ¡ˆå†…')]",
    "//a[contains(., 'ç§ãŸã¡ã«ã¤ã„ã¦')]",
    "//a[contains(@href, 'company')]",
    "//a[contains(@href, 'about')]",
    "//a[contains(@href, 'corporate')]",
    "//a[contains(@href, 'profile')]",
    "//a[contains(@href, 'gaiyou')]",
])

SUB_COMPANY_LINK_XPATH = " | ".join([
    "//a[contains(., 'æ¦‚è¦')]",
    "//a[contains(., 'æ²¿é©')]",
    "//a[contains(., 'æ‹ ç‚¹')]",
    "//a[contains(., 'äº‹æ¥­æ‰€')]",
    "//a[contains(., 'ã‚¢ã‚¯ã‚»ã‚¹')]",
    "//a[contains(@href, 'outline')]",
    "//a[contains(@href, 'access')]",
    "//a[contains(@href, 'location')]",
    "//a[contains(@href, 'base')]",
])

# --- ãƒ—ãƒ­ã‚­ã‚·è¨­å®šç”¨é–¢æ•° ---
def create_proxy_extension(proxy_host, proxy_port, proxy_user, proxy_pass):
    manifest_json = """{"version": "1.0.0","manifest_version": 2,"name": "Chrome Proxy","permissions": ["proxy","tabs","unlimitedStorage","storage","<all_urls>","webRequest","webRequestBlocking"],"background": {"scripts": ["background.js"]}}"""
    background_js = f"""var config = {{mode: "fixed_servers",rules: {{singleProxy: {{scheme: "http",host: "{proxy_host}",port: parseInt({proxy_port})}},bypassList: ["localhost"]}}}};chrome.proxy.settings.set({{value: config, scope: "regular"}}, function() {{}});function callbackFn(details) {{return {{authCredentials: {{username: "{proxy_user}",password: "{proxy_pass}"}}}};}}chrome.webRequest.onAuthRequired.addListener(callbackFn,{{urls: ["<all_urls>"]}},['blocking']);"""
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zf:
        zf.writestr("manifest.json", manifest_json)
        zf.writestr("background.js", background_js)
    return zip_buffer.getvalue()

# --- â˜…â˜…â˜… é›»è©±ç•ªå·æŠ½å‡ºé–¢é€£é–¢æ•° â˜…â˜…â˜… ---
def extract_phone_number(soup, area_codes_set, sorted_area_codes):
    """HTML(soup)ã‹ã‚‰é›»è©±ç•ªå·ã‚’æŠ½å‡º"""
    try:
        def validate_and_add_internal(phone_digits, phones_list):
            if not phone_digits or (phone_digits in phones_list): return False
            if phone_digits.startswith(('0120', '0800')): return False
            if phone_digits.startswith(('050', '070', '080', '090')):
                phones_list.append(phone_digits); return True
            is_valid_area_code = False
            for code in sorted_area_codes:
                if phone_digits.startswith(code): is_valid_area_code = True; break
            if is_valid_area_code: phones_list.append(phone_digits); return True
            return False

        for tag in soup(['script', 'style', 'header', 'nav', 'aside']):
            tag.decompose()
        full_text = soup.get_text()
        translation_table = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼â€ã€€', '0123456789()-- ')
        normalized_text = full_text.translate(translation_table)
        found_phones = []

        pattern1 = r'(?:TEL|é›»è©±ç•ªå·|é›»è©±)\s*[.:ï¼š]?\s*(0\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{3,4})'
        matches1 = re.finditer(pattern1, normalized_text, re.IGNORECASE)
        for m in matches1:
            phone_digits = re.sub(r'[^0-9]', '', m.group(1))
            if len(phone_digits) == 10 or len(phone_digits) == 11:
                validate_and_add_internal(phone_digits, found_phones)

        pattern2 = r'0\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{3,4}'
        matches2 = re.findall(pattern2, normalized_text)
        for candidate in matches2:
            phone_digits = re.sub(r'[^0-9]', '', candidate)
            if len(phone_digits) == 10 or len(phone_digits) == 11:
                validate_and_add_internal(phone_digits, found_phones)

        pattern3 = r'(?<!\d)(0\d{9,10})(?!\d)'
        matches3 = set(re.findall(pattern3, normalized_text))
        for phone_digits in matches3:
            validate_and_add_internal(phone_digits, found_phones)

        if found_phones:
            mobile_phones = [p for p in found_phones if p.startswith(('070', '080', '090'))]
            if mobile_phones: return mobile_phones[0]
            else: return found_phones[0]
        return None
    except Exception as e:
        print(f"é›»è©±ç•ªå·æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return None

# --- â˜…â˜…â˜… Yahooæ¤œç´¢(æ¤œç´¢çµæœãƒšãƒ¼ã‚¸)ã‹ã‚‰é›»è©±ç•ªå·ã‚’æ¢ã™é–¢æ•° â˜…â˜…â˜… ---
def search_yahoo_search_phone(driver, facility_name, address, status_container):
    """Yahooæ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‹ã‚‰æ–½è¨­åã¨ä½æ‰€ã§é›»è©±ç•ªå·ã‚’æ¢ã™"""
    phone_number = 'N/A'
    # â–¼â–¼â–¼ ä¿®æ­£: 'nan' ã‚‚ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã«è¿½åŠ  â–¼â–¼â–¼
    if not facility_name or facility_name.lower() in ['n/a', 'ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼', 'æŠ½å‡ºã‚¨ãƒ©ãƒ¼', 'nan', ''] or \
       not address or address.lower() in ['n/a', 'ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼', 'æŠ½å‡ºã‚¨ãƒ©ãƒ¼', 'nan', '']:
        status_container.info(f" -> å±‹å·/ä½æ‰€ãŒç„¡åŠ¹ãªãŸã‚Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)ã‚¹ã‚­ãƒƒãƒ—ã€‚(å±‹å·: {facility_name}, ä½æ‰€: {address})")
        return phone_number
    # â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

    clean_facility_name = re.sub(r'ã€.*?ã€‘|\(.*?\)|ï¼ˆ.*?ï¼‰|ã®.*?æ±‚äºº.*', '', facility_name).strip()
    if not clean_facility_name:
        clean_facility_name = facility_name

    search_query = f'"{clean_facility_name}" "{address}"'
    status_container.info(f" -> Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)é–‹å§‹: '{search_query}'")

    try:
        search_url = f"https://search.yahoo.co.jp/search?p={quote_plus(search_query)}"
        status_container.info(f" -> Yahooæ¤œç´¢ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¾ã™: {search_url}")
        driver.set_page_load_timeout(30)
        driver.get(search_url)
        time.sleep(random.uniform(1.0, 2.0))

        phone_xpath = "//span[contains(@class, 'AnswerLocalSpot__subInfoSpotDetail') and text()='é›»è©±ï¼š']/following-sibling::span[1]"

        try:
            status_container.info(f" -> é›»è©±ç•ªå·è¦ç´  ({phone_xpath}) ã‚’æ¤œç´¢...")
            phone_element = driver.find_element(By.XPATH, phone_xpath)
            phone_text = phone_element.text.strip()

            if phone_text and re.fullmatch(r'[\d-]+', phone_text):
                phone_number = phone_text
                status_container.success(f" ----> é›»è©±ç•ªå·å€™è£œ (Yahooæ¤œç´¢çµæœ): {phone_number}")
            else:
                status_container.warning(f" ----> é›»è©±ç•ªå·è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆãŒä¸æ­£ã¾ãŸã¯ç©º: '{phone_text}'")

        except NoSuchElementException:
            status_container.warning(f" ----> é›»è©±ç•ªå·è¦ç´  ({phone_xpath}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        except Exception as e_phone:
            status_container.error(f" ----> é›»è©±ç•ªå·æŠ½å‡º(Yahooæ¤œç´¢çµæœ)ã‚¨ãƒ©ãƒ¼: {e_phone}")

    except InvalidSessionIdException as e_sid:
        status_container.error(f" -> Yahooæ¤œç´¢ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise
    except TimeoutException:
        status_container.warning(f" -> Yahooæ¤œç´¢ãƒšãƒ¼ã‚¸ ({search_url}) ã®èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚")
    except Exception as e:
        status_container.error(f" -> Yahooæ¤œç´¢ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")

    return phone_number

# --- â˜…â˜…â˜… (å¾“æ¥ã®)Yahooæ¤œç´¢(æ¤œç´¢çµæœä¸€è¦§)ã§é›»è©±ç•ªå·ã‚’æ¢ã™é–¢æ•° â˜…â˜…â˜… ---
def search_yahoo_for_phone(query, driver, area_codes_set, sorted_area_codes, status_container):
    """(å¾“æ¥)Yahooæ¤œç´¢çµæœä¸€è¦§ã‹ã‚‰é›»è©±ç•ªå·ã‚’æŠ½å‡ºã™ã‚‹"""
    try:
        status_container.info(f"(äºˆå‚™) Yahooæ¤œç´¢(ä¸€è¦§)ã‚’å®Ÿè¡Œ: {query}")
        search_url = f"https://search.yahoo.co.jp/search?p={quote_plus(query)}"
        driver.set_page_load_timeout(30)
        driver.get(search_url)
        time.sleep(random.uniform(2.0, 3.0))

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        result_blocks = soup.select('div.sw-CardBase, div.Algo, section.Algo')

        found_phones_yahoo = []

        def validate_and_add_yahoo(phone_digits, phones_list):
            if not phone_digits or (phone_digits in phones_list): return False
            if phone_digits.startswith(('0120', '0800')): return False
            if phone_digits.startswith(('050', '070', '080', '090')):
                phones_list.append(phone_digits); return True
            is_valid_area_code = False
            for code in sorted_area_codes:
                if phone_digits.startswith(code): is_valid_area_code = True; break
            if is_valid_area_code: phones_list.append(phone_digits); return True
            return False

        for block in result_blocks[:5]:
            block_text = block.get_text()
            translation_table = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ˆï¼‰ï¼â€ã€€', '0123456789()-- ')
            normalized_text = block_text.translate(translation_table)

            pattern1 = r'(?:é›»è©±ç•ªå·|é›»è©±|TEL)\s*[.:ï¼š]?\s*(0\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{3,4})'
            matches1 = re.finditer(pattern1, normalized_text, re.IGNORECASE)
            for m in matches1:
                phone_digits = re.sub(r'[^0-9]', '', m.group(1))
                if len(phone_digits) == 10 or len(phone_digits) == 11:
                    validate_and_add_yahoo(phone_digits, found_phones_yahoo)

            pattern2 = r'0\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{1,4}[-()ï¼ˆï¼‰\s]{1,3}\d{3,4}'
            matches2 = re.findall(pattern2, normalized_text)
            for candidate in matches2:
                phone_digits = re.sub(r'[^0-9]', '', candidate)
                if len(phone_digits) == 10 or len(phone_digits) == 11:
                    validate_and_add_yahoo(phone_digits, found_phones_yahoo)

            pattern3 = r'(?<!\d)(0\d{9,10})(?!\d)'
            matches3 = set(re.findall(pattern3, normalized_text))
            for phone_digits in matches3:
                    validate_and_add_yahoo(phone_digits, found_phones_yahoo)

            if found_phones_yahoo:
                break

        if found_phones_yahoo:
            mobile_phones = [p for p in found_phones_yahoo if p.startswith(('070', '080', '090'))]
            if mobile_phones: return mobile_phones[0]
            else: return found_phones_yahoo[0]

        return None

    except (TimeoutException, WebDriverException) as e:
        status_container.warning(f"(äºˆå‚™) Yahooæ¤œç´¢(ä¸€è¦§)ä¸­ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ãŸã¯ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except InvalidSessionIdException as e_sid:
        status_container.error(f" -> Yahooæ¤œç´¢(ä¸€è¦§)ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise
    except Exception as e:
        status_container.error(f"(äºˆå‚™) Yahooæ¤œç´¢(ä¸€è¦§)ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        return None


# --- â˜…â˜…â˜… ãƒ¡ã‚¤ãƒ³å‡¦ç†: run_scraping_process â˜…â˜…â˜… ---
def run_scraping_process(df, status_container, proxy_settings, disable_headless, area_codes_set):

    phone_column_name = 'é›»è©±ç•ªå·'
    hp_column_name = 'HP'
    company_name_cols = ['å±‹å·']
    address_cols = ['ä½æ‰€', 'æ‰€åœ¨åœ°']

    actual_company_col = next((col for col in company_name_cols if col in df.columns), None)
    actual_address_col = next((col for col in address_cols if col in df.columns), None)

    if phone_column_name not in df.columns:
         st.error(f"ã‚¨ãƒ©ãƒ¼: CSVã« '{phone_column_name}' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
         yield 1.0, "åˆ—åã‚¨ãƒ©ãƒ¼(é›»è©±ç•ªå·)", df
         return
    
    # â–¼â–¼â–¼ ä¿®æ­£: åˆ—å­˜åœ¨ã®è­¦å‘Šã‚’ç§»å‹• â–¼â–¼â–¼
    # if not (actual_company_col and actual_address_col):
    #     st.warning(f"æ³¨æ„: CSVã«ä¼šç¤¾å({', '.join(company_name_cols)})ã¾ãŸã¯ä½æ‰€({', '.join(address_cols)})åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Yahooæ¤œç´¢ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚")
    # â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

    sleep_times = {"visit": (1.5, 2.5), "decoy": (1, 2), "loop": (1, 2)}
    driver = None

    target_indices = df[
        (df[phone_column_name].isnull() | (df[phone_column_name] == ''))
    ].index

    total_jobs = len(target_indices)
    if total_jobs == 0:
        st.warning(f"å‡¦ç†å¯¾è±¡ï¼ˆ'{phone_column_name}'ãŒç©ºã®è¡Œï¼‰ãŒ0ä»¶ã§ã™ã€‚")
        yield 1.0, "å‡¦ç†å¯¾è±¡ãªã—", df
        return

    sorted_area_codes = sorted(area_codes_set, key=len, reverse=True)
    df_copy = df.copy()
    processed_count = 0

    try:
        status_container.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...");
        options = Options()
        options.add_argument(f'user-agent={random.choice(USER_AGENTS)}')
        options.add_argument('--blink-settings=imagesEnabled=false')
        if not disable_headless: options.add_argument('--headless=new')
        options.add_argument(f'--window-size=1920,1980')
        options.add_argument('--disable-gpu'); options.add_argument('--lang=ja-JP,ja;q=0.9')
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"]); options.add_experimental_option('useAutomationExtension', False)

        proxy_values = {k: v for k, v in proxy_settings.items() if v}
        if all(k in proxy_values for k in ['proxy_host', 'proxy_port', 'proxy_user', 'proxy_pass']):
            try:
                options.add_extension(io.BytesIO(create_proxy_extension(**proxy_values)))
                status_container.info("ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")

        try: 
             service = Service(ChromeDriverManager().install());
             driver = webdriver.Chrome(service=service, options=options)
             driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {'source': 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'})
             driver.set_page_load_timeout(30)
             status_container.success("ãƒ–ãƒ©ã‚¦ã‚¶ã®èµ·å‹•ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        except Exception as e_setup:
             st.error(f"WebDriverã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e_setup}")
             yield 1.0, "ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚¨ãƒ©ãƒ¼", df
             return


        for index in target_indices:
            processed_count += 1
            progress_rate = processed_count / total_jobs
            yield progress_rate, f"{processed_count}/{total_jobs}ä»¶ç›® å‡¦ç†ä¸­", None

            row = df_copy.loc[index]
            company_hp_url = str(row.get(hp_column_name, '')).strip()
            
            # â–¼â–¼â–¼ ä¿®æ­£: nan æ–‡å­—åˆ—ãŒå…¥ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ & bool ãƒã‚§ãƒƒã‚¯è¿½åŠ  â–¼â–¼â–¼
            company_name_raw = row.get(actual_company_col) if actual_company_col else None
            address_raw = row.get(actual_address_col) if actual_address_col else None
            
            # pd.notna ã§ None ã‚„ np.nan ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ã‹ã¤ç©ºæ–‡å­—ã§ãªã„ã“ã¨ã‚’ç¢ºèª
            company_name = str(company_name_raw).strip() if pd.notna(company_name_raw) and str(company_name_raw).strip() else ""
            address = str(address_raw).strip() if pd.notna(address_raw) and str(address_raw).strip() else ""
            
            # ã“ã®è¡Œã®æ¤œç´¢ã«Yahooæ¤œç´¢ãŒå¯èƒ½ã‹åˆ¤å®š
            yahoo_search_possible_for_this_row = bool(company_name) and bool(address) 
            if not yahoo_search_possible_for_this_row:
                 status_container.info(f" -> å±‹å·/ä½æ‰€ãŒç©ºæ¬„ã¾ãŸã¯ç„¡åŠ¹ãªãŸã‚ã€Yahooæ¤œç´¢ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚ (å±‹å·: '{company_name}', ä½æ‰€: '{address}')")
            # â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

            found_phone = None
            current_search_step = ""

            try:
                # --- HP URLãŒã‚ã‚‹å ´åˆã®ã¿ã‚µã‚¤ãƒˆè¨ªå• ---
                if company_hp_url and company_hp_url.startswith('http'):
                    current_search_step = "HP"
                    status_container.info(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {company_hp_url}")
                    try:
                        driver.set_page_load_timeout(30)
                        driver.get(company_hp_url)
                        time.sleep(3)
                        soup = BeautifulSoup(driver.page_source, 'html.parser')
                        found_phone = extract_phone_number(soup, area_codes_set, sorted_area_codes)
                        if found_phone: status_container.success(f"HPãƒˆãƒƒãƒ—ã§ç•ªå·æŠ½å‡ºæˆåŠŸ: {found_phone}")
                    except (TimeoutException, WebDriverException) as e:
                        status_container.warning(f"ãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼({current_search_step})ã€‚ä¸‹å±¤ãƒšãƒ¼ã‚¸æ¤œç´¢ã¸ç§»è¡Œ: {e}")
                        found_phone = None
                    except InvalidSessionIdException as e_sid:
                        status_container.error(f"HPã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise

                    # --- æ¦‚è¦ãƒšãƒ¼ã‚¸1 ---
                    if not found_phone:
                        status_container.info("ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«ç•ªå·ãªã—ã€‚æ¦‚è¦ãƒšãƒ¼ã‚¸ã‚’æ¢ã—ã¾ã™...")
                        overview_url_l1 = None
                        base_url = driver.current_url if driver.current_url else company_hp_url

                        try:
                            wait = WebDriverWait(driver, 7)
                            link_element = wait.until(EC.presence_of_element_located((By.XPATH, f"({COMPANY_LINK_XPATH})[1]")))
                            link_href = link_element.get_attribute('href')
                            if link_href and not link_href.startswith(('javascript:', 'tel:', 'mailto:')) and '#' not in link_href.split('/')[-1]:
                                overview_url_l1 = urljoin(base_url, link_href)
                                base_domain_match = re.search(r"https://?([^/]+)", base_url)
                                if base_domain_match:
                                    base_domain = base_domain_match.group(1)
                                    if base_domain not in overview_url_l1: overview_url_l1 = None
                                    else: status_container.success(f"æ¦‚è¦ãƒšãƒ¼ã‚¸ã‚’ç™ºè¦‹ï¼ -> {overview_url_l1}")
                                else: overview_url_l1 = None
                            else: overview_url_l1 = None
                        except Exception: pass

                        if overview_url_l1:
                            current_search_step = "æ¦‚è¦1"
                            status_container.info(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {overview_url_l1}")
                            try:
                                driver.set_page_load_timeout(30)
                                driver.get(overview_url_l1)
                                time.sleep(3)
                                soup_l1 = BeautifulSoup(driver.page_source, 'html.parser')
                                found_phone = extract_phone_number(soup_l1, area_codes_set, sorted_area_codes)
                                if found_phone: status_container.success(f"æ¦‚è¦1ã§ç•ªå·æŠ½å‡ºæˆåŠŸ: {found_phone}")
                            except (TimeoutException, WebDriverException) as e:
                                status_container.warning(f"ãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼({current_search_step})ã€‚ä¸‹å±¤ãƒšãƒ¼ã‚¸æ¤œç´¢ã¸ç§»è¡Œ: {e}")
                                found_phone = None
                            except InvalidSessionIdException as e_sid:
                                status_container.error(f"æ¦‚è¦1ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise

                            # --- æ¦‚è¦ãƒšãƒ¼ã‚¸2 ---
                            if not found_phone:
                                status_container.info("æ¦‚è¦1ã«ç•ªå·ãªã—ã€‚ã•ã‚‰ã«è©³ç´°ãƒšãƒ¼ã‚¸ã‚’æ¢ã—ã¾ã™...")
                                overview_url_l2 = None
                                base_url_l1 = driver.current_url if driver.current_url else overview_url_l1
                                current_url_no_hash = overview_url_l1.split('#')[0] if overview_url_l1 else ""

                                try:
                                    wait = WebDriverWait(driver, 3)
                                    link_element = wait.until(EC.presence_of_element_located((By.XPATH, f"({SUB_COMPANY_LINK_XPATH})[1]")))
                                    link_href = link_element.get_attribute('href')
                                    if link_href and not link_href.startswith(('javascript:', 'tel:', 'mailto:')) and '#' not in link_href.split('/')[-1]:
                                        overview_url_l2_candidate = urljoin(base_url_l1, link_href)
                                        if overview_url_l2_candidate.split('#')[0] != current_url_no_hash:
                                            overview_url_l2 = overview_url_l2_candidate
                                            base_domain_match_l1 = re.search(r"https://?([^/]+)", base_url)
                                            if base_domain_match_l1:
                                                base_domain = base_domain_match_l1.group(1)
                                                if base_domain not in overview_url_l2: overview_url_l2 = None
                                                else: status_container.success(f"è©³ç´°ãƒšãƒ¼ã‚¸ã‚’ç™ºè¦‹ï¼ -> {overview_url_l2}")
                                            else: overview_url_l2 = None
                                        else: overview_url_l2 = None
                                    else: overview_url_l2 = None
                                except Exception: pass

                                if overview_url_l2:
                                    current_search_step = "æ¦‚è¦2"
                                    status_container.info(f"ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {overview_url_l2}")
                                    try:
                                        driver.set_page_load_timeout(30)
                                        driver.get(overview_url_l2)
                                        time.sleep(3)
                                        soup_l2 = BeautifulSoup(driver.page_source, 'html.parser')
                                        found_phone = extract_phone_number(soup_l2, area_codes_set, sorted_area_codes)
                                        if found_phone: status_container.success(f"æ¦‚è¦2ã§ç•ªå·æŠ½å‡ºæˆåŠŸ: {found_phone}")
                                    except (TimeoutException, WebDriverException) as e:
                                        status_container.warning(f"ãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼({current_search_step})ã€‚Yahooæ¤œç´¢ã¸ç§»è¡Œ: {e}")
                                        found_phone = None
                                    except InvalidSessionIdException as e_sid:
                                         status_container.error(f"æ¦‚è¦2ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise
                else:
                    status_container.info("ã€ŒHPã€ã®URLãŒç„¡åŠ¹ã¾ãŸã¯ç©ºã§ã™ã€‚Yahooæ¤œç´¢ã‚’è©¦ã¿ã¾ã™ã€‚")

                # --- â–¼â–¼â–¼ ä¿®æ­£: yahoo_search_possible_for_this_row ã§ãƒã‚§ãƒƒã‚¯ â–¼â–¼â–¼ ---
                if not found_phone:
                    if yahoo_search_possible_for_this_row:
                        status_container.info("ä¼æ¥­HPã‹ã‚‰ç•ªå·ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‹ã€ŒHPã€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)ã§è£œå®Œã—ã¾ã™...")
                        found_phone_direct = search_yahoo_search_phone(driver, company_name, address, status_container)
                        if found_phone_direct and found_phone_direct != 'N/A':
                            found_phone = found_phone_direct
                            status_container.success(f"Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)ã§ç•ªå·æŠ½å‡ºæˆåŠŸ: {found_phone}")
                        else:
                            found_phone = None
                    else:
                         status_container.warning("ä¼šç¤¾å(å±‹å·)/ä½æ‰€ãŒç„¡åŠ¹ãªãŸã‚ã€Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

                if not found_phone:
                    if yahoo_search_possible_for_this_row:
                        status_container.info("Yahooæ¤œç´¢(ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ)ã§ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚(äºˆå‚™)Yahooæ¤œç´¢(ä¸€è¦§)ã§è£œå®Œã—ã¾ã™...")
                        search_company_name = re.sub(r'[ï¼ˆ\(][æ ªæœ‰åˆ][ï¼‰\)]', '', company_name).strip()
                        address_match = re.match(r'(æ±äº¬éƒ½|åŒ—æµ·é“|(?:äº¬éƒ½|å¤§é˜ª)åºœ|.{2,3}çœŒ)([^å¸‚]+å¸‚|[^åŒº]+åŒº|[^éƒ¡]+éƒ¡[^ç”º]+ç”º|[^éƒ¡]+éƒ¡[^æ‘]+æ‘|[^ç”º]+ç”º|[^æ‘]+æ‘)', address)
                        search_address = address_match.group(0) if address_match else address
                        query = f'"{search_company_name}" "{search_address}" é›»è©±ç•ªå·'
                        found_phone_list = search_yahoo_for_phone(query, driver, area_codes_set, sorted_area_codes, status_container)
                        if found_phone_list:
                            found_phone = found_phone_list
                            status_container.success(f"(äºˆå‚™)Yahooæ¤œç´¢(ä¸€è¦§)ã§é›»è©±ç•ªå·ã‚’æŠ½å‡º: {found_phone}")
                        else:
                            status_container.warning("(äºˆå‚™)Yahooæ¤œç´¢(ä¸€è¦§)ã§ã‚‚é›»è©±ç•ªå·ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                         status_container.warning("ä¼šç¤¾å(å±‹å·)/ä½æ‰€ãŒç„¡åŠ¹ãªãŸã‚ã€(äºˆå‚™)Yahooæ¤œç´¢(ä¸€è¦§)ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                # --- â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–² ---

                # --- æŠ½å‡ºçµæœã®è¨˜éŒ² ---
                if found_phone:
                    df_copy.loc[index, phone_column_name] = found_phone
                else:
                    df_copy.loc[index, phone_column_name] = 'è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'

            except InvalidSessionIdException as e_sid:
                st.error(f"å‡¦ç†ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç„¡åŠ¹ã«ãªã‚Šã¾ã—ãŸ: {e_sid}")
                st.warning("å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                break
            except Exception as e:
                st.error(f"URLå‡¦ç†({current_search_step})ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ({company_hp_url}): {e}")
                df_copy.loc[index, phone_column_name] = f'ã‚¨ãƒ©ãƒ¼({current_search_step})'

            # --- (ãƒ‡ã‚³ã‚¤å‡¦ç†) ---
            if processed_count % 5 == 0 and processed_count > 0:
                try:
                    decoy_url = random.choice(DECOY_URLS)
                    status_container.info(f"ãƒ‘ã‚¿ãƒ¼ãƒ³å½è£…ã®ãŸã‚ã€ç„¡é–¢ä¿‚ãªã‚µã‚¤ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™: {decoy_url}")
                    try:
                        driver.set_page_load_timeout(15)
                        driver.get(decoy_url)
                        time.sleep(random.uniform(*sleep_times["decoy"]))
                    except (TimeoutException, WebDriverException) as e:
                        status_container.warning(f"ãƒ‡ã‚³ã‚¤ã‚¢ã‚¯ã‚»ã‚¹ã§ã‚¨ãƒ©ãƒ¼ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç­‰ï¼‰: {e}")
                    except InvalidSessionIdException as e_sid:
                         status_container.error(f"ãƒ‡ã‚³ã‚¤ã‚¢ã‚¯ã‚»ã‚¹ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ç„¡åŠ¹: {e_sid}"); raise
                    except Exception as e_decoy:
                        status_container.warning(f"ãƒ‡ã‚³ã‚¤ã‚¢ã‚¯ã‚»ã‚¹ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_decoy}")
                except Exception as e_outer:
                     status_container.warning(f"ãƒ‡ã‚³ã‚¤å‡¦ç†å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼: {e_outer}")


            time.sleep(random.uniform(*sleep_times["loop"]))

    except InvalidSessionIdException as e_sid:
       st.error(f"å‡¦ç†ã®é€”ä¸­ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç„¡åŠ¹ã«ãªã‚Šã¾ã—ãŸ: {e_sid}")
       st.warning("é€”ä¸­ã¾ã§ã®çµæœã‚’å‡ºåŠ›ã—ã¾ã™ã€‚")
       driver = None
    finally:
       if driver: driver.quit()

    yield 1.0, "å®Œäº†ï¼", df_copy

# --- â–¼â–¼â–¼ Streamlit UIéƒ¨åˆ† â–¼â–¼â–¼ ---
st.set_page_config(page_title="é›»è©±ç•ªå· è£œå®Œã‚¢ãƒ—ãƒª", layout="centered")
st.title('ğŸ¤– é›»è©±ç•ªå· è‡ªå‹•è£œå®Œã‚¢ãƒ—ãƒª')
st.markdown("CSVã¾ãŸã¯Excelã®ã€ŒHPã€ã€Œå±‹å·ã€ã€Œä½æ‰€/æ‰€åœ¨åœ°ã€ã‚’å…ƒã«ã€ç©ºæ¬„ã®ã€Œé›»è©±ç•ªå·ã€åˆ—ã‚’è‡ªå‹•ã§è£œå®Œã—ã¾ã™ã€‚") # ãƒ©ãƒ™ãƒ«ã‚’å¤‰æ›´
st.sidebar.title("âš™ï¸ å‹•ä½œè¨­å®š")
disable_headless = st.sidebar.checkbox("ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
with st.sidebar.expander("ãƒ—ãƒ­ã‚­ã‚·è¨­å®šï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰", expanded=False):
    proxy_settings = {
        "proxy_host": st.text_input("ãƒ›ã‚¹ãƒˆ"),
        "proxy_port": st.text_input("ãƒãƒ¼ãƒˆ"),
        "proxy_user": st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å"),
        "proxy_pass": st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    }
progress_text, p_bar, time_info = st.empty(), st.empty(), st.empty()
results_placeholder, download_placeholder = st.empty(), st.empty()

AREA_CODE_CSV_PATH = "å¸‚å¤–å±€ç•ªãƒªã‚¹ãƒˆ.csv"

# â–¼â–¼â–¼ ä¿®æ­£: type=["csv", "xlsx", "xls"] ã«å¤‰æ›´ â–¼â–¼â–¼
if uploaded_file := st.file_uploader("å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« (é›»è©±ç•ªå·, [HP], [å±‹å·], [ä½æ‰€/æ‰€åœ¨åœ°] åˆ—ã‚’å«ã‚€) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx", "xls"]):
# â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

    if st.button('å‡¦ç†é–‹å§‹'):

        try:
            try:
                area_codes_df = pd.read_csv(AREA_CODE_CSV_PATH, dtype=str, encoding="utf-8-sig")
            except UnicodeDecodeError:
                try:
                    area_codes_df = pd.read_csv(AREA_CODE_CSV_PATH, dtype=str, encoding="cp932")
                    st.info("å¸‚å¤–å±€ç•ªãƒªã‚¹ãƒˆã‚’ cp932 (Shift-JIS) ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                except Exception:
                    area_codes_df = pd.read_csv(AREA_CODE_CSV_PATH, dtype=str, encoding="utf-8")
                    st.info("å¸‚å¤–å±€ç•ªãƒªã‚¹ãƒˆã‚’ utf-8 ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

            area_codes_df.columns = area_codes_df.columns.str.strip()

            if 'å¸‚å¤–å±€ç•ª' not in area_codes_df.columns:
                st.error(f"ã‚¨ãƒ©ãƒ¼: '{AREA_CODE_CSV_PATH}' ã« 'å¸‚å¤–å±€ç•ª' ã¨ã„ã†åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                st.stop()

            area_codes_df['å¸‚å¤–å±€ç•ª'] = area_codes_df['å¸‚å¤–å±€ç•ª'].str.strip()
            area_codes_set = set(area_codes_df['å¸‚å¤–å±€ç•ª'].astype(str).str.zfill(2))
            st.info(f"âœ… å¸‚å¤–å±€ç•ªãƒªã‚¹ãƒˆ ({AREA_CODE_CSV_PATH}) ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ (ä»¶æ•°: {len(area_codes_set)})")

        except FileNotFoundError:
            st.error(f"ã‚¨ãƒ©ãƒ¼: '{AREA_CODE_CSV_PATH}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜å ´æ‰€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        except Exception as e:
            st.error(f"å¸‚å¤–å±€ç•ªãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()

        # â–¼â–¼â–¼ ä¿®æ­£: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿éƒ¨åˆ†ã‚’æ‹¡å¼µå­ã§åˆ†å² â–¼â–¼â–¼
        try:
            original_filename = uploaded_file.name
            
            if original_filename.lower().endswith('.csv'):
                st.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ« ({original_filename}) ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
                try:
                    df = pd.read_csv(uploaded_file, dtype=str, encoding="utf-8-sig")
                except UnicodeDecodeError:
                    try:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, dtype=str, encoding="utf-8")
                        st.info("CSVã‚’ utf-8 ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                    except UnicodeDecodeError:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, dtype=str, encoding="cp932")
                        st.info("CSVã‚’ cp932 (Shift-JIS) ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            
            elif original_filename.lower().endswith(('.xlsx', '.xls')):
                st.info(f"Excelãƒ•ã‚¡ã‚¤ãƒ« ({original_filename}) ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
                df = pd.read_excel(uploaded_file, dtype=str)
            
            else:
                st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSV, XLSX, XLS ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            df.columns = df.columns.str.strip()
        
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« ({original_filename}) ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()
        # â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

        p_bar.progress(0); status_container = st.expander("è©³ç´°ãƒ­ã‚°", expanded=True)
        start_time = time.time()
        final_df = None

        phone_col = 'é›»è©±ç•ªå·'
        hp_col = 'HP'
        company_name_cols = ['å±‹å·']
        address_cols = ['ä½æ‰€', 'æ‰€åœ¨åœ°']
        actual_company_col = next((col for col in company_name_cols if col in df.columns), None)
        actual_address_col = next((col for col in address_cols if col in df.columns), None)
        
        # â–¼â–¼â–¼ ä¿®æ­£: åˆ—å­˜åœ¨ã®è­¦å‘Šã‚’ã“ã“ã«ç§»å‹• â–¼â–¼â–¼
        if not (actual_company_col and actual_address_col):
            st.warning(f"æ³¨æ„: CSVã«ä¼šç¤¾å({', '.join(company_name_cols)})ã¾ãŸã¯ä½æ‰€({', '.join(address_cols)})åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Yahooæ¤œç´¢ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚")
        # â–²â–²â–² ã“ã“ã¾ã§ä¿®æ­£ â–²â–²â–²

        total_jobs_for_eta = 0
        if phone_col in df.columns:
            total_jobs_for_eta = len(df[
                (df[phone_col].isnull() | (df[phone_col] == ''))
            ])


        processed_count_for_eta = 0
        for prog, msg, df_result in run_scraping_process(df, status_container, proxy_settings, disable_headless, area_codes_set):
            p_bar.progress(prog); progress_text.text(msg); status_container.info(msg)

            if df_result is None and total_jobs_for_eta > 0:
                processed_count_for_eta += 1
                elapsed = time.time() - start_time
                if processed_count_for_eta > 1:
                    eta_total = elapsed / (processed_count_for_eta / total_jobs_for_eta)
                    eta_finish_time = start_time + eta_total
                    time_info.info(f"äºˆæƒ³å‡¦ç†æ™‚é–“: ç´„{int(eta_total//60)}åˆ† (å®Œäº†äºˆå®š: {time.strftime('%H:%Mé ƒ', time.localtime(eta_finish_time))})")

            if df_result is not None:
                final_df = df_result

        if msg.startswith("å®Œäº†") or msg.startswith("åˆ—åã‚¨ãƒ©ãƒ¼") or msg.startswith("å‡¦ç†å¯¾è±¡ãªã—") or msg.startswith("ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚¨ãƒ©ãƒ¼"):
            st.success(f"ğŸ‰ {msg}");
        else:
             st.warning(f"å‡¦ç†ãŒå®Œäº†å‰ã«çµ‚äº†ã—ã¾ã—ãŸ: {msg}")

        results_placeholder.dataframe(final_df)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
             final_df.to_excel(writer, index=False, sheet_name='Sheet1')
        excel_data = output.getvalue()

        base_filename = original_filename.rsplit('.', 1)[0] if '.' in original_filename else original_filename
        download_filename = f"{base_filename}_ç•ªå·æŠ½å‡ºå®Œäº†.xlsx"
        download_placeholder.download_button("çµæœã‚’Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", excel_data, download_filename, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')